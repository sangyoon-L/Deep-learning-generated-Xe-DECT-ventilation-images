{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "Count of using GPUs: 1\n",
      "Current cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    \n",
    "    Invertd,\n",
    "    Resized,\n",
    "    EnsureTyped,\n",
    "    ToTensord,\n",
    "    Lambdad\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import natsort\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai import data, transforms\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.data import NumpyReader\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import gc\n",
    "import GPUtil\n",
    "from monai.inferers import sliding_window_inference\n",
    "import pydicom\n",
    "import re\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "import glob\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): NLayerDiscriminator(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc=2, output_nc=1, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        encoder_model = [nn.ReflectionPad2d(3),\n",
    "                         nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                         norm_layer(ngf),\n",
    "                         nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            encoder_model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                              norm_layer(ngf * mult * 2),\n",
    "                              nn.ReLU(True)]\n",
    "\n",
    "        self.encoder_model = nn.Sequential(*encoder_model)\n",
    "\n",
    "        self.map_decoder = self.map_build_decoder(ngf, output_nc, norm_layer, use_bias, n_downsampling, n_blocks)\n",
    "        self.emph_decoder = self.build_decoder(ngf, 2, norm_layer, use_bias, n_downsampling, n_blocks)\n",
    "\n",
    "    def map_build_decoder(self, ngf, output_nc, norm_layer, use_bias, n_downsampling, n_blocks):\n",
    "        decoder_model = []\n",
    "        \n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "            decoder_model += [ResnetBlock(ngf*mult, padding_type='reflect', norm_layer=norm_layer, use_dropout=False, use_bias=use_bias)]\n",
    "        \n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            decoder_model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                                 kernel_size=3, stride=2,\n",
    "                                                 padding=1, output_padding=1,\n",
    "                                                 bias=use_bias),\n",
    "                              norm_layer(int(ngf * mult / 2)),\n",
    "                              nn.ReLU(True)]\n",
    "            \n",
    "        decoder_model += [nn.ReflectionPad2d(3)]\n",
    "        decoder_model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        decoder_model += [nn.Tanh()]\n",
    "\n",
    "        return nn.Sequential(*decoder_model)\n",
    "    \n",
    "    def build_decoder(self, ngf, output_nc, norm_layer, use_bias, n_downsampling, n_blocks):\n",
    "        decoder_model = []\n",
    "        \n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            decoder_model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                                 kernel_size=3, stride=2,\n",
    "                                                 padding=1, output_padding=1,\n",
    "                                                 bias=use_bias),\n",
    "                              norm_layer(int(ngf * mult / 2)),\n",
    "                              nn.ReLU(True)]\n",
    "            \n",
    "        decoder_model += [nn.ReflectionPad2d(3)]\n",
    "        decoder_model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        decoder_model += [nn.Tanh()]\n",
    "\n",
    "        return nn.Sequential(*decoder_model)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder_model(input)\n",
    "        return self.map_decoder(encoded), self.emph_decoder(encoded)\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc=1, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, img_A):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        img_input = img_A\n",
    "        return self.model(img_input)\n",
    "    \n",
    "generator = ResnetGenerator().apply(weights_init_normal)\n",
    "discriminator = NLayerDiscriminator().apply(weights_init_normal)\n",
    "\n",
    "model = nn.DataParallel(generator, device_ids=[0])\n",
    "model.to(device)\n",
    "\n",
    "discriminator = nn.DataParallel(discriminator, device_ids=[0])\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working...\n",
      "42600\n",
      "5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([256, 256]), label shape: torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "def list_sort_nicely(l):\n",
    "    def tryint(s):\n",
    "        try:\n",
    "            return int(s)\n",
    "        except:\n",
    "            return s\n",
    "    \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s)]\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l\n",
    "\n",
    "print(\"working...\")\n",
    "\n",
    "map_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/map/*/*.dcm\"\n",
    "vnc_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/vnc_wi/*/*.dcm\"\n",
    "vnc_wo_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/vnc_wo/*/*.dcm\"\n",
    "emph_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/emp/*/*.dcm\"\n",
    "\n",
    "map_wis = list_sort_nicely((glob.glob(map_wi_dir)))\n",
    "vnc_wis = list_sort_nicely((glob.glob(vnc_wi_dir)))\n",
    "vnc_wos = list_sort_nicely((glob.glob(vnc_wo_dir)))\n",
    "emphs = list_sort_nicely((glob.glob(emph_dir)))\n",
    "data_dicts = [{\"map_wi\": map_wi_name, \"vnc_wi\": vnc_wi_name, \"vnc_wo\": vnc_wo_name, \"emph\": emph_name} for map_wi_name, vnc_wi_name, vnc_wo_name, emph_name in zip(map_wis, vnc_wis, vnc_wos, emphs)]\n",
    "train_files = data_dicts\n",
    "\n",
    "map_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/valid/map/*/*.dcm\"\n",
    "vnc_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/valid/vnc_wi/*/*.dcm\"\n",
    "vnc_wo_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/valid/vnc_wo/*/*.dcm\"\n",
    "emph_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/valid/emp/*/*.dcm\"\n",
    "\n",
    "map_wis = list_sort_nicely((glob.glob(map_wi_dir)))\n",
    "vnc_wis = list_sort_nicely((glob.glob(vnc_wi_dir)))\n",
    "vnc_wos = list_sort_nicely((glob.glob(vnc_wo_dir)))\n",
    "emphs = list_sort_nicely((glob.glob(emph_dir)))\n",
    "data_dicts = [{\"map_wi\": map_wi_name, \"vnc_wi\": vnc_wi_name, \"vnc_wo\": vnc_wo_name, \"emph\": emph_name} for map_wi_name, vnc_wi_name, vnc_wo_name, emph_name in zip(map_wis, vnc_wis, vnc_wos, emphs)]\n",
    "val_files = data_dicts\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(val_files))\n",
    "\n",
    "def squeeze(image):\n",
    "    image = image.squeeze()\n",
    "    return image\n",
    "\n",
    "data_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\", \"emph\"]),\n",
    "        Lambdad(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\", \"emph\"], func=squeeze),\n",
    "        EnsureChannelFirstd(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\", \"emph\"]),\n",
    "        ScaleIntensityRanged(keys=[\"vnc_wi\", \"vnc_wo\"], a_min=-1024.0, a_max=-100.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ScaleIntensityRanged(keys=[\"map_wi\"], a_min=0.0, a_max=50.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        #AddChanneld(keys=[\"image\"]),\n",
    "        #Resized(keys=['image'], spatial_size=[1,224,224]),\n",
    "        Resized(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\", \"emph\"], spatial_size=[256,256]),\n",
    "        EnsureTyped(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\", \"emph\"]),\n",
    "        ToTensord(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\", \"emph\"])]\n",
    ")\n",
    "\n",
    "check_ds = Dataset(data=val_files, transform=data_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "vnc_wi, vnc_wo, map_wi= (check_data[\"vnc_wi\"][0][0], check_data[\"vnc_wo\"][0][0], check_data[\"map_wi\"][0][0])\n",
    "print(f\"image shape: {vnc_wi.shape}, label shape: {vnc_wo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=data_transforms, cache_rate=2.0, num_workers=8)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=data_transforms, cache_rate=2.0, num_workers=8)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "class LambdaLR:\n",
    "    def __init__(self, n_epochs, decay_start_epoch):\n",
    "        self.n_epochs = n_epochs \n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "b1 = 0.5                \n",
    "b2 = 0.999  \n",
    "lr = 0.0002\n",
    "lambda_pixel = 100\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_emph = torch.optim.Adam(model.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_G = torch.optim.Adam(model.parameters(), lr=lr, betas=(b1,b2))\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "seg_loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "dice_metric_emphy = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "n_epochs = 600 \n",
    "decay_epoch = 200 \n",
    "lr = 0.0002 \n",
    "\n",
    "lr_scheduler_emph = torch.optim.lr_scheduler.LambdaLR(optimizer_emph, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "\n",
    "emphy_metric = 0\n",
    "\n",
    "val_interval = 2\n",
    "train_check_interval = 2\n",
    "save_interval = 2\n",
    "\n",
    "emphy_post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "emphy_post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "epoch_emphy_loss = []\n",
    "epoch_D_map_loss = []\n",
    "epoch_G_map_loss = []\n",
    "emphy_metric_values = []\n",
    "epoch_val_loss = []\n",
    "\n",
    "best_emphy_metric = -1\n",
    "best_emphy_metric_epoch = -1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"training started...\")\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    step =0\n",
    "    emphy_loss = 0\n",
    "    G_map_loss = 0\n",
    "    D_map_loss =0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        step+=1\n",
    "        # Model inputs\n",
    "        real_vnc_wi = batch[\"vnc_wi\"].to(device)\n",
    "        real_vnc_wo = batch[\"vnc_wo\"].to(device)\n",
    "        real_emphy_mask = batch[\"emph\"].to(device)\n",
    "        real_map_wi = batch[\"map_wi\"].to(device)\n",
    "        \n",
    "        real_A_cat = torch.cat((real_vnc_wi, real_vnc_wo),1)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(torch.ones(vnc_wi.size()).to(device), requires_grad=False)\n",
    "        fake = Variable(torch.zeros(vnc_wi.size()).to(device), requires_grad=False)\n",
    "        \n",
    "        # ------------------\n",
    "        # Train Emphysema Segmentation\n",
    "        # ------------------\n",
    "        \n",
    "        optimizer_emph.zero_grad()\n",
    "        \n",
    "        map_fake, emphy_mask = model(real_A_cat)\n",
    "        loss_emph = seg_loss_function(emphy_mask, real_emphy_mask)\n",
    "        loss_emph.backward()\n",
    "        \n",
    "        optimizer_emph.step()\n",
    "        \n",
    "        # ------------------\n",
    "        #  Train MAP Generators\n",
    "        # ------------------\n",
    "        \n",
    "        # GAN loss\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        map_fake, emphy_mask = model(real_A_cat)\n",
    "        pred_fake = discriminator(map_fake)\n",
    "        \n",
    "        loss_GAN = criterion_GAN(pred_fake, Variable(torch.ones(pred_fake.size()).to(device), requires_grad=False))\n",
    "        \n",
    "        # Pixel-wise loss\n",
    "        loss_pixel = criterion_pixelwise(map_fake, real_map_wi)\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = discriminator(real_map_wi)\n",
    "        loss_real = criterion_GAN(pred_real, Variable(torch.ones(pred_real.size()).to(device), requires_grad=False))\n",
    "\n",
    "        # Fake loss\n",
    "        pred_fake = discriminator(map_fake.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, Variable(torch.zeros(pred_fake.size()).to(device), requires_grad=False))\n",
    "        \n",
    "        # Total loss\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        \n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \"\"\" loss values \"\"\"\n",
    "        emphy_loss += loss_emph.item()\n",
    "        G_map_loss += loss_G.item()\n",
    "        D_map_loss += loss_D.item()\n",
    "        \n",
    "        if i % 50 ==0:\n",
    "            print(\"\\n\")\n",
    "            print(\"Epoch\",f\"{epoch}\", \"#\",f\"{i}/{len(train_loader)}\",\"iteration\", \"Elapsed time:\", f\"{(time.time() - start_time)/60:.2f}\", \"min\")\n",
    "            print(\"Emphysema SEG loss:\", loss_emph, \"MAP Generator loss:\", loss_G, \"MAP Discriminator loss:\", loss_D)\n",
    "    \n",
    "    emphy_loss /= step\n",
    "    G_map_loss /= step\n",
    "    D_map_loss /= step\n",
    "    \n",
    "    epoch_emphy_loss.append(emphy_loss)\n",
    "    epoch_D_map_loss.append(D_map_loss)\n",
    "    epoch_G_map_loss.append(G_map_loss)\n",
    "    \n",
    "    lr_scheduler_emph.step()\n",
    "    lr_scheduler_D.step()    \n",
    "    lr_scheduler_G.step()  \n",
    "    \n",
    "    if epoch % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_loss_epoch = []\n",
    "        num =0\n",
    "        for j, batch in enumerate(val_loader):\n",
    "            num+=1\n",
    "            real_vnc_wi = batch[\"vnc_wi\"].to(device)\n",
    "            real_vnc_wo = batch[\"vnc_wo\"].to(device)\n",
    "            real_emphy_mask = batch[\"emph\"].to(device)\n",
    "            real_map_wi = batch[\"map_wi\"].to(device)\n",
    "            \n",
    "            real_A_cat = torch.cat((real_vnc_wi, real_vnc_wo),1)\n",
    "            map_fake, emphy_mask = model(real_A_cat)\n",
    "            \n",
    "            \n",
    "            val_loss = lambda_pixel * criterion_pixelwise(real_map_wi, map_fake)\n",
    "            val_loss_epoch.append(val_loss.detach().cpu())\n",
    "            if j % 500 == 0:\n",
    "                plt.figure(\"real\", (12, 6))\n",
    "                plt.subplot(1, 4, 1)\n",
    "                plt.title(\"vnc_wi\")\n",
    "                plt.imshow(np.rot90(real_vnc_wi.detach().cpu().squeeze(),k=3), cmap=\"gray\")\n",
    "                plt.subplot(1, 4, 2)\n",
    "                plt.title(\"vnc_wo\")\n",
    "                plt.imshow(np.rot90(real_vnc_wo.detach().cpu().squeeze(),k=3), cmap=\"gray\")\n",
    "                plt.subplot(1, 4, 3)\n",
    "                plt.title(\"map_wi\")\n",
    "                plt.imshow(np.rot90(real_map_wi.detach().cpu().squeeze(),k=3), cmap=\"gray\")\n",
    "                plt.subplot(1, 4, 4)\n",
    "                plt.title(\"emph\")\n",
    "                plt.imshow(np.rot90(real_emphy_mask.cpu().squeeze(),k=3))\n",
    "                plt.savefig(f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/val{j}_real_epoch{epoch}.png\", bbox_inches = 'tight')\n",
    "\n",
    "                plt.figure(\"outputs\", (12, 6))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.title(\"fake_map\")\n",
    "                plt.imshow(np.rot90(map_fake.detach().cpu().squeeze(),k=3), cmap=\"gray\")\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.title(\"emphy_SEG\")\n",
    "                plt.imshow(np.rot90(torch.argmax(emphy_mask[0,:,:].squeeze(), dim=0).detach().cpu(),k=3))\n",
    "                plt.savefig(f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/val{j}_output_epoch{epoch}.png\", bbox_inches = 'tight')\n",
    "            \n",
    "                print(f\"[Val: {j}/{len(val_loader)}] [Elapsed time: {(time.time() - start_time)/60:.2f}min]\")\n",
    "            \n",
    "            emphy_mask_ = [emphy_post_pred(i) for i in decollate_batch(emphy_mask)]\n",
    "            real_emphy_mask_ = [emphy_post_label(i) for i in decollate_batch(real_emphy_mask)]\n",
    "            dice_metric_emphy(y_pred=emphy_mask_, y=real_emphy_mask_)\n",
    "            \n",
    "        \n",
    "        # aggregate the final mean dice result\n",
    "        emphy_metric = dice_metric_emphy.aggregate().item()\n",
    "        # reset the status for next validation round\n",
    "        dice_metric_emphy.reset()\n",
    "        \n",
    "        emphy_metric_values.append(emphy_metric)\n",
    "        \n",
    "        if emphy_metric > best_emphy_metric:\n",
    "            best_emphy_metric = emphy_metric\n",
    "            best_emphy_metric_epoch = epoch + 1\n",
    "            print(\"saved new best metric model for Emphysema\")\n",
    "            \n",
    "        print(\n",
    "                f\"current epoch: {epoch + 1} current Emphysema mean dice: {emphy_metric:.4f}\"\n",
    "                f\"\\nbest Emphysema mean dice: {best_emphy_metric:.4f} \"\n",
    "                f\"at epoch: {best_emphy_metric_epoch}\"\n",
    "            )\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        torch.save(model.state_dict(), f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/epoch{epoch}_model.pth\")\n",
    "        torch.save(discriminator.state_dict(), f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/epoch{epoch}_D.pth\")\n",
    "    \n",
    "    if epoch % train_check_interval == 0:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        X = [i+1 for i in range(len(epoch_emphy_loss))]\n",
    "        Y = epoch_emphy_loss\n",
    "        plt.plot(X,Y, label=\"emphy_loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/SEG_train_loss.png\", bbox_inches = 'tight')\n",
    "        \n",
    "        plt.figure(figsize=(8,6))\n",
    "        Y =  epoch_D_map_loss\n",
    "        plt.plot(X,Y, label=\"D_loss\")\n",
    "        \n",
    "        Y =  epoch_G_map_loss\n",
    "        plt.plot(X,Y, label=\"G_loss\")\n",
    "        plt.title(\"MAP Generator, Discriminator loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/MAP_train_loss.png\", bbox_inches = 'tight')\n",
    "    \n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.title(\"Val Mean Dice\")\n",
    "        x = [val_interval * (i + 1) for i in range(len(emphy_metric_values))]\n",
    "        y = emphy_metric_values\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.plot(x, y, label = 'emphysema dice score')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitask_vanilla_gan2/Val_mean_dice_epoch.png\", bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
