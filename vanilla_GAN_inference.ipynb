{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  4% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "Count of using GPUs: 1\n",
      "Current cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    Resized,\n",
    "    EnsureTyped,\n",
    "    ToTensord,\n",
    "    Lambdad\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import natsort\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai import data, transforms\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.data import NumpyReader\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import gc\n",
    "import GPUtil\n",
    "from monai.inferers import sliding_window_inference\n",
    "import pydicom\n",
    "import re\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "import glob\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResnetGenerator(\n",
       "    (model): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(2, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (21): ReLU(inplace=True)\n",
       "      (22): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (23): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (24): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# U-NET 생성\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc=2, output_nc=1, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc=2, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, img_A):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        img_input = img_A\n",
    "        return self.model(img_input)\n",
    "    \n",
    "generator = ResnetGenerator().apply(weights_init_normal)\n",
    "discriminator = NLayerDiscriminator().apply(weights_init_normal)\n",
    "\n",
    "discriminator = nn.DataParallel(discriminator, device_ids=[0])\n",
    "discriminator.to(device)\n",
    "\n",
    "model = nn.DataParallel(generator, device_ids=[0])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working...\n",
      "42600\n",
      "6000\n",
      "image shape: torch.Size([256, 256]), label shape: torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "def list_sort_nicely(l):\n",
    "    def tryint(s):\n",
    "        try:\n",
    "            return int(s)\n",
    "        except:\n",
    "            return s\n",
    "    \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s)]\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l\n",
    "\n",
    "print(\"working...\")\n",
    "\n",
    "map_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/map/*/*.dcm\"\n",
    "vnc_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/vnc_wi/*/*.dcm\"\n",
    "vnc_wo_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/train/vnc_wo/*/*.dcm\"\n",
    "\n",
    "map_wis = list_sort_nicely((glob.glob(map_wi_dir)))\n",
    "vnc_wis = list_sort_nicely((glob.glob(vnc_wi_dir)))\n",
    "vnc_wos = list_sort_nicely((glob.glob(vnc_wo_dir)))\n",
    "data_dicts = [{\"map_wi\": map_wi_name, \"vnc_wi\": vnc_wi_name, \"vnc_wo\": vnc_wo_name, \"map_wi_name\": map_wi_name} for map_wi_name, vnc_wi_name, vnc_wo_name, map_wi_name in zip(map_wis, vnc_wis, vnc_wos, map_wis)]\n",
    "train_files = data_dicts\n",
    "\n",
    "map_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/test/map/*/*.dcm\"\n",
    "vnc_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/test/vnc_wi/*/*.dcm\"\n",
    "vnc_wo_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/test/vnc_wo/*/*.dcm\"\n",
    "\n",
    "map_wis = list_sort_nicely((glob.glob(map_wi_dir)))\n",
    "vnc_wis = list_sort_nicely((glob.glob(vnc_wi_dir)))\n",
    "vnc_wos = list_sort_nicely((glob.glob(vnc_wo_dir)))\n",
    "data_dicts = [{\"map_wi\": map_wi_name, \"vnc_wi\": vnc_wi_name, \"vnc_wo\": vnc_wo_name, \"map_wi_name\": map_wi_name} for map_wi_name, vnc_wi_name, vnc_wo_name, map_wi_name in zip(map_wis, vnc_wis, vnc_wos, map_wis)]\n",
    "test_files = data_dicts\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(test_files))\n",
    "\n",
    "def squeeze(image):\n",
    "    image = image.squeeze()\n",
    "    return image\n",
    "\n",
    "data_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"]),\n",
    "        Lambdad(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"], func=squeeze),\n",
    "        EnsureChannelFirstd(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"]),\n",
    "        ScaleIntensityRanged(keys=[\"vnc_wi\", \"vnc_wo\"], a_min=-1024.0, a_max=-100.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ScaleIntensityRanged(keys=[\"map_wi\"], a_min=0.0, a_max=50.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        #AddChanneld(keys=[\"image\"]),\n",
    "        #Resized(keys=['image'], spatial_size=[1,224,224]),\n",
    "        Resized(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"], spatial_size=[256,256]),\n",
    "        EnsureTyped(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"]),\n",
    "        ToTensord(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"])]\n",
    ")\n",
    "\n",
    "check_ds = Dataset(data=test_files, transform=data_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "vnc_wi, vnc_wo, map_wi= (check_data[\"vnc_wi\"][0][0], check_data[\"vnc_wo\"][0][0], check_data[\"map_wi\"][0][0])\n",
    "print(f\"image shape: {vnc_wi.shape}, label shape: {vnc_wo.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = CacheDataset(data=train_files, transform=data_transforms, cache_rate=2.0, num_workers=8)\n",
    "#train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "test_ds = CacheDataset(data=test_files, transform=data_transforms, cache_rate=2.0, num_workers=8)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "root_dir = \"/mnt/nas203/forGPU/leesangy/final_inference/vanilla_gan/\"\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"epoch22_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "discriminator.load_state_dict(torch.load(os.path.join(root_dir, \"epoch22_D.pth\")))\n",
    "discriminator.eval()\n",
    "\n",
    "start_time = time.time()\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "\n",
    "print(\"test started...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        map_wi = batch[\"map_wi\"].to(device)\n",
    "        real_vnc_wi = batch[\"vnc_wi\"].to(device)\n",
    "        real_vnc_wo = batch[\"vnc_wo\"].to(device)\n",
    "        map_wi_name = batch[\"map_wi_name\"][0][-16:-4]\n",
    "        \n",
    "        mask = np.rot90(map_wi.detach().cpu().squeeze(), k=3)\n",
    "        mask[mask > 0] = 1\n",
    "        mask[mask < 0] = 0\n",
    "        \n",
    "        #plt.imshow(mask)\n",
    "        #plt.show()\n",
    "        \n",
    "        real_A_cat = torch.cat((real_vnc_wi, real_vnc_wo),1)\n",
    "        map_fake = model(real_A_cat)\n",
    "        \n",
    "        test_outputs= np.rot90(map_fake.detach().cpu().numpy().squeeze(),k=3)\n",
    "        test_outputs = test_outputs * mask\n",
    "        test_outputs[test_outputs <0] =1e-5\n",
    "        test_outputs = test_outputs * mask\n",
    "        image = nib.Nifti1Image(np.rot90(test_outputs, k=3), affine=np.eye(4))\n",
    "        \n",
    "        nib.save(image, f\"/mnt/nas203/forGPU/leesangy/final_inference/vanilla_gan/test22/nifti/{map_wi_name}.nii.gz\")\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(i, (time.time()-start_time)/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
