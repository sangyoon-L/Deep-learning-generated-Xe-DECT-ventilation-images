{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "Count of using GPUs: 1\n",
      "Current cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    Resized,\n",
    "    EnsureTyped,\n",
    "    ToTensord,\n",
    "    Lambdad\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import natsort\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai import data, transforms\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.data import NumpyReader\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import gc\n",
    "import GPUtil\n",
    "from monai.inferers import sliding_window_inference\n",
    "import pydicom\n",
    "import re\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "import glob\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResnetGenerator(\n",
       "    (encoder_model): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(2, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "    )\n",
       "    (map_decoder): Sequential(\n",
       "      (0): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (13): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (14): Tanh()\n",
       "    )\n",
       "    (emph_decoder): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (7): Conv2d(64, 2, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (8): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc=2, output_nc=1, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        encoder_model = [nn.ReflectionPad2d(3),\n",
    "                         nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                         norm_layer(ngf),\n",
    "                         nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            encoder_model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                              norm_layer(ngf * mult * 2),\n",
    "                              nn.ReLU(True)]\n",
    "\n",
    "        self.encoder_model = nn.Sequential(*encoder_model)\n",
    "\n",
    "        self.map_decoder = self.map_build_decoder(ngf, output_nc, norm_layer, use_bias, n_downsampling, n_blocks)\n",
    "        self.emph_decoder = self.build_decoder(ngf, 2, norm_layer, use_bias, n_downsampling, n_blocks)\n",
    "\n",
    "    def map_build_decoder(self, ngf, output_nc, norm_layer, use_bias, n_downsampling, n_blocks):\n",
    "        decoder_model = []\n",
    "        \n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "            decoder_model += [ResnetBlock(ngf*mult, padding_type='reflect', norm_layer=norm_layer, use_dropout=False, use_bias=use_bias)]\n",
    "        \n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            decoder_model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                                 kernel_size=3, stride=2,\n",
    "                                                 padding=1, output_padding=1,\n",
    "                                                 bias=use_bias),\n",
    "                              norm_layer(int(ngf * mult / 2)),\n",
    "                              nn.ReLU(True)]\n",
    "            \n",
    "        decoder_model += [nn.ReflectionPad2d(3)]\n",
    "        decoder_model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        decoder_model += [nn.Tanh()]\n",
    "\n",
    "        return nn.Sequential(*decoder_model)\n",
    "    \n",
    "    def build_decoder(self, ngf, output_nc, norm_layer, use_bias, n_downsampling, n_blocks):\n",
    "        decoder_model = []\n",
    "        \n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            decoder_model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                                 kernel_size=3, stride=2,\n",
    "                                                 padding=1, output_padding=1,\n",
    "                                                 bias=use_bias),\n",
    "                              norm_layer(int(ngf * mult / 2)),\n",
    "                              nn.ReLU(True)]\n",
    "            \n",
    "        decoder_model += [nn.ReflectionPad2d(3)]\n",
    "        decoder_model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        decoder_model += [nn.Tanh()]\n",
    "\n",
    "        return nn.Sequential(*decoder_model)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder_model(input)\n",
    "        return self.map_decoder(encoded), self.emph_decoder(encoded)\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc=3, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "    \n",
    "generator = ResnetGenerator().apply(weights_init_normal)\n",
    "discriminator = NLayerDiscriminator().apply(weights_init_normal)\n",
    "\n",
    "discriminator = nn.DataParallel(discriminator, device_ids=[0,1])\n",
    "discriminator.to(device)\n",
    "\n",
    "model = nn.DataParallel(generator, device_ids=[0,1])\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working...\n",
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([256, 256]), label shape: torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "def list_sort_nicely(l):\n",
    "    def tryint(s):\n",
    "        try:\n",
    "            return int(s)\n",
    "        except:\n",
    "            return s\n",
    "    \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s)]\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l\n",
    "\n",
    "print(\"working...\")\n",
    "\n",
    "map_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/test/map/*/*.dcm\"\n",
    "vnc_wi_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/test/vnc_wi/*/*.dcm\"\n",
    "vnc_wo_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_dataset/test/vnc_wo/*/*.dcm\"\n",
    "#emph_dir = \"/mnt/nas203/forGPU/leesangy/final_dataset/test/emp/*/*.dcm\"\n",
    "\n",
    "map_wis = list_sort_nicely((glob.glob(map_wi_dir)))\n",
    "vnc_wis = list_sort_nicely((glob.glob(vnc_wi_dir)))\n",
    "vnc_wos = list_sort_nicely((glob.glob(vnc_wo_dir)))\n",
    "#emphs = list_sort_nicely((glob.glob(emph_dir)))\n",
    "\n",
    "data_dicts = [{\"map_wi\": map_wi_name, \"vnc_wi\": vnc_wi_name, \"vnc_wo\": vnc_wo_name, \"map_wi_name\": map_wi_name} for map_wi_name, vnc_wi_name, vnc_wo_name, map_wi_name in zip(map_wis, vnc_wis, vnc_wos, map_wis)]\n",
    "test_files = data_dicts\n",
    "\n",
    "print(len(test_files))\n",
    "\n",
    "def squeeze(image):\n",
    "    image = image.squeeze()\n",
    "    return image\n",
    "\n",
    "data_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"]),\n",
    "        Lambdad(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"], func=squeeze),\n",
    "        EnsureChannelFirstd(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"]),\n",
    "        ScaleIntensityRanged(keys=[\"vnc_wi\", \"vnc_wo\"], a_min=-1024.0, a_max=-100.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ScaleIntensityRanged(keys=[\"map_wi\"], a_min=0.0, a_max=50.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        #AddChanneld(keys=[\"image\"]),\n",
    "        #Resized(keys=['image'], spatial_size=[1,224,224]),\n",
    "        Resized(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"], spatial_size=[256,256]),\n",
    "        EnsureTyped(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"]),\n",
    "        ToTensord(keys=[\"map_wi\", \"vnc_wi\", \"vnc_wo\"])]\n",
    ")\n",
    "\n",
    "check_ds = Dataset(data=test_files, transform=data_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "vnc_wi, vnc_wo, map_wi = (check_data[\"vnc_wi\"][0][0], check_data[\"vnc_wo\"][0][0], check_data[\"map_wi\"][0][0])\n",
    "print(f\"image shape: {vnc_wi.shape}, label shape: {vnc_wo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = CacheDataset(data=train_files, transform=data_transforms, cache_rate=2.0, num_workers=8)\n",
    "#train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "root_dir = \"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitasking_G_256/\"\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"epoch22_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "discriminator.load_state_dict(torch.load(os.path.join(root_dir, \"epoch22_D.pth\")))\n",
    "discriminator.eval()\n",
    "\n",
    "test_ds = CacheDataset(data=test_files, transform=data_transforms, cache_rate=2.0, num_workers=8)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "import time\n",
    "\n",
    "print(\"test started...\")\n",
    "\n",
    "time_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        map_wi = batch[\"map_wi\"].to(device)\n",
    "        real_vnc_wi = batch[\"vnc_wi\"].to(device)\n",
    "        real_vnc_wo = batch[\"vnc_wo\"].to(device)\n",
    "        map_wi_name = batch[\"map_wi_name\"][0][-16:-4]\n",
    "        \n",
    "        mask = np.rot90(map_wi.detach().cpu().squeeze(), k=3)\n",
    "        mask[mask > 0] = 1\n",
    "        mask[mask < 0] = 0\n",
    "        \n",
    "        #plt.imshow(mask)\n",
    "        #plt.show()\n",
    "        \n",
    "        real_A_cat = torch.cat((real_vnc_wi, real_vnc_wo),1)\n",
    "        #start_time = time.time()\n",
    "        map_fake, emph_mask = model(real_A_cat)\n",
    "        #time_one_slice = time.time()-start_time\n",
    "        #print(time_one_slice, \"sec\")\n",
    "        #time_list.append(time_one_slice)\n",
    "        \n",
    "        test_outputs= np.rot90(map_fake.detach().cpu().numpy().squeeze(),k=3)\n",
    "        test_outputs = test_outputs * mask\n",
    "        test_outputs[test_outputs <0] =1e-5\n",
    "        test_outputs = test_outputs * mask\n",
    "        image = nib.Nifti1Image(np.rot90(test_outputs, k=3), affine=np.eye(4))\n",
    "        \n",
    "        nib.save(image, f\"/mnt/nas203/forGPU/leesangy/Task_VQ_mismatch/final_inference/multitasking_G_256/test/nifti/{map_wi_name}.nii.gz\")\n",
    "\n",
    "        if i % 199 == 0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8347554206848145\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(time_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
